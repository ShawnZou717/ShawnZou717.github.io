<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://shawnzou717.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://shawnzou717.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2023-08-07T15:50:01+08:00</updated><id>https://shawnzou717.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Transformer Analysis</title><link href="https://shawnzou717.github.io/blog/2023/transformer-analysis/" rel="alternate" type="text/html" title="Transformer Analysis"/><published>2023-08-03T11:57:00+08:00</published><updated>2023-08-03T11:57:00+08:00</updated><id>https://shawnzou717.github.io/blog/2023/transformer-analysis</id><content type="html" xml:base="https://shawnzou717.github.io/blog/2023/transformer-analysis/"><![CDATA[<h2 id="table-of-contents">Table of Contents</h2> <ul> <li><a href="#table-of-contents">Table of Contents</a></li> <li><a href="#transformer-architecture">Transformer Architecture</a></li> </ul> <p>Among all the deep learning models, Transformer can be the most widely talked over one thanks to the tremendous performance that ChatGPT, a Transformer-based model, has shown in being a personal assistant and chatbot. Never heard of it? Let’s take a look at ChatGPT’s own words.</p> <figure> <figcaption>Ask ChatGPT to introduce the Transformer model</figcaption> <img src="../assets/img/transformer-analysis/try-chatGPT.png" width="540"/> </figure> <p>Transformer’s application extends way out of NLP domain. As a powerful mathematical tool, it has helped us in DNA recognition, medical research and many aspects in other research area. I believe it is safe to say that one day we may all need to apply this model in our project. Thus, a solid understanding of Transformer architecture is neccesary. To this end, this blog focuses on a comprehensive introduction of Transformer.</p> <h2 id="transformer-architecture">Transformer Architecture</h2> <p>In 2017, Google posted a paper named <a href="https://arxiv.org/abs/1706.03762v4">Attention is All You Need</a> in arXiv bringing Transformer into history. Though Transformer follows the <code class="language-plaintext highlighter-rouge">seq2seq</code> structure (also known as <code class="language-plaintext highlighter-rouge">decoders and encoders</code>), its encoders and decoders consist of sole <code class="language-plaintext highlighter-rouge">self-attention</code> modules instead of <code class="language-plaintext highlighter-rouge">RNN</code> and <code class="language-plaintext highlighter-rouge">CNN</code> like most other NLP models. This is exactly the origin of the article title, a neural network composed entirely of <code class="language-plaintext highlighter-rouge">self-attention</code> mechanisms. Now let’s take the classic Transformer as an example reviewing the unique model introduced by Transformer.</p> <figure> <figcaption>Simplified Transformer Structure</figcaption> <img src="../assets/img/transformer-analysis/transformer-arch.png" width="540"/> </figure> <p>As illustrated above, Transformer has 6 encoders and 6 decoders. Encoder</p>]]></content><author><name></name></author><category term="deep-learning"/><category term="Transformer"/><summary type="html"><![CDATA[a plain introduction of Transformer and professional derivation of its backward propagation]]></summary></entry></feed>