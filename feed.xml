<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://shawnzou717.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://shawnzou717.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-09-26T11:34:39+08:00</updated><id>https://shawnzou717.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">BUGS While Running WW3 Model Quick Start</title><link href="https://shawnzou717.github.io/blog/2023/ww3-quick-start-bug/" rel="alternate" type="text/html" title="BUGS While Running WW3 Model Quick Start"/><published>2023-09-22T14:00:00+08:00</published><updated>2023-09-22T14:00:00+08:00</updated><id>https://shawnzou717.github.io/blog/2023/ww3-quick-start-bug</id><content type="html" xml:base="https://shawnzou717.github.io/blog/2023/ww3-quick-start-bug/"><![CDATA[<h2 id="ww3-quick-start">WW3 Quick Start</h2> <p>WW3 can be the most widely used wave model in meteorological prediction and reanalysis. This model directly comes from the very frontier research’s keyboard. Focusing more on research function rather than commercial operation, thus it is totally user unfriendly, even if you run the very first quick start demo given in the munual, errors could occur quite frequent. Here I am recording 2 bugs I have met.</p> <p>As the manual states, there are only 2 steps before you can compile and run ww3 model.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># set up compiler and forecast mode</span>
model/bin/w3_setup model <span class="nt">-c</span> gnu <span class="nt">-s</span> NCEP_st4

<span class="c"># download data via ftp</span>
model/bin/ww3_from_ftp.sh
</code></pre></div></div> <p>Now, you can start compiling.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>model/bin/w3_make
</code></pre></div></div> <p>I saw 2 bugs before I complete compilation. Here I descripe what is the feature and solution of each error.</p> <p>##</p>]]></content><author><name></name></author><category term="physical-oceanography"/><category term="ww3"/><summary type="html"><![CDATA[a review of Coriolis force]]></summary></entry><entry><title type="html">Coriolis Force</title><link href="https://shawnzou717.github.io/blog/2023/coriolis-force/" rel="alternate" type="text/html" title="Coriolis Force"/><published>2023-09-13T14:00:00+08:00</published><updated>2023-09-13T14:00:00+08:00</updated><id>https://shawnzou717.github.io/blog/2023/coriolis-force</id><content type="html" xml:base="https://shawnzou717.github.io/blog/2023/coriolis-force/"><![CDATA[<h2 id="derivation-of-coriolis-force">Derivation of Coriolis Force</h2> <hr/> <p>Supposing that we have 2 coordinates whoes origins both locate at the center of the Earth. The red one is absolutely static and the green one rotates along with our planet. See below.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/coriolis-force/inertial-coordinate-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/coriolis-force/inertial-coordinate-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/coriolis-force/inertial-coordinate-1400.webp"/> <img src="/assets/img/coriolis-force/inertial-coordinate.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/coriolis-force/rotating-coordinate-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/coriolis-force/rotating-coordinate-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/coriolis-force/rotating-coordinate-1400.webp"/> <img src="/assets/img/coriolis-force/rotating-coordinate.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Now, assuming that there is a car running on the street at \(\overrightarrow{v_0}\) to the policeman’s eyes. Well, if we view this scene from the space view, the velocity in our eyes should be the sum of the rotation speed of the earth and the car running along the street. That gives us:</p> \[\overrightarrow{v}=\overrightarrow{v_0}+\overrightarrow{\omega}\times\overrightarrow{r_0}\] <p>Therefore the acceleration with respect to the static coordinate is</p> \[\begin{aligned} \overrightarrow{a}&amp;=\frac{d\overrightarrow{v}}{dt} + \overrightarrow{\omega}\times\overrightarrow{v}\\ &amp;=\frac{d\overrightarrow{v_0}}{dt}+\overrightarrow{\omega}\times\frac{d\overrightarrow{r_0}}{dt}+\overrightarrow{\omega}\times\overrightarrow{v_0} +\overrightarrow{\omega}\times\overrightarrow{\omega}\times\overrightarrow{r_0}\\ &amp;=\frac{d^2\overrightarrow{r_0}}{dt^2}+2\overrightarrow{\omega}\times\frac{d\overrightarrow{r_0}}{dt} +\overrightarrow{\omega}\times\overrightarrow{\omega}\times\overrightarrow{r_0} \end{aligned}\] <p>Following the traditions in Physics, the second and third term is usually set to be negative. In this way, Earth’s surface objects experience a net external force of</p> \[\overrightarrow{F'}=\overrightarrow{F}-(-2m\overrightarrow{\omega}\times\frac{d\overrightarrow{r_0}}{dt})-(-m\overrightarrow{\omega}\times\overrightarrow{\omega}\times\overrightarrow{r_0})\] <p>Where the second term is so called <code class="language-plaintext highlighter-rouge">Coriolis Force</code>, i.e. \(\overrightarrow{C}=-2m\overrightarrow{\omega}\times\frac{d\overrightarrow{r_0}}{dt}\).</p> <p>Though we see this Coriolis term in the net force of an object, there isn’t real such a force exerted by some other objects to the one we focus on. More likely, this term origins the mathematical consistency while mapping physical vectors from a rotating coordinate to the inertial coordinate.</p> <h2 id="coriolis-induced-turning-effect">Coriolis-induced Turning Effect</h2> <p>There are already conlusions about the motion distortion effect induced by the Coriolis force. Such as, the objects in the North hemisphere experiences a Coriolis force to the right in the direction of motion, while objects from the South hemisphere are subjected to a left side Coriolis force. Why is that? Now let’s try to explain it with some basic calculations.</p> <p>First, we switch to a surface coordinate on our planet. The <code class="language-plaintext highlighter-rouge">y</code> axis goes along the longitude to north pole and the <code class="language-plaintext highlighter-rouge">x</code> axis goes along the latitude from West to East, making our <code class="language-plaintext highlighter-rouge">z</code> axis rises towards the sky. Refer to the following figure.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/coriolis-force/surface-coordinate-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/coriolis-force/surface-coordinate-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/coriolis-force/surface-coordinate-1400.webp"/> <img src="/assets/img/coriolis-force/surface-coordinate.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>We let the angular velocity in the given coordinate be like \(\overrightarrow{\omega}=\omega_y\overrightarrow{j}+\omega_z\overrightarrow{k}\). Since the angular velocity is perpendicular to the equator plane, \(\overrightarrow{\omega_x}\) must equal to 0. And if we were at the North hemisphere, the angular z component must be no smaller than 0 while in the South hemisphere, z component remain smaller than or equal 0. Check out the table for details.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/coriolis-force/angular-components-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/coriolis-force/angular-components-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/coriolis-force/angular-components-1400.webp"/> <img src="/assets/img/coriolis-force/angular-components.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Now, imagine that the object only moves along the xoy plane, that gives us \(\overrightarrow{v_0}=v_x\overrightarrow{i}+v_y\overrightarrow{j}\). Simply substitude the object velocity and angular velocity into the Coriolis force expression, we get</p> \[\begin{aligned} \overrightarrow{C}&amp;=-2m(\omega_y\overrightarrow{j}+\omega_z\overrightarrow{k})\times(v_x\overrightarrow{i}+v_y\overrightarrow{j})\\ &amp;=2m(\omega_z v_y\overrightarrow{i}-\omega_z v_x\overrightarrow{j} +\omega_y v_x\overrightarrow{k}) \end{aligned}\] <p>Here, we ignore the force component along the z axis. See what if we dot times the rest force and the object velocity. You can easily see that</p> \[\overrightarrow{C}_{xoy}\cdot \overrightarrow{v_0}=2m(\omega_z v_y v_x-\omega_z v_x v_y)=0\] <p>Shockingly, we see the horizontal component of the coriolis force always is perpendicular to the object velocity, and if we go further, let’s assume that \(v_y=0\), we would have that \(\overrightarrow{C}=-2m\omega_z v_x\overrightarrow{j}\) and \(\overrightarrow{v_0}=v_x\overrightarrow{i}\). Apart from the always identical parameter \(v_x\) and always positive parameter \(2m\), we can see that the location of coriolis force is determined by z-component angular velocity.</p> <p>Wow! Then according to the above table, in the North hemisphere, the coriolis force are always locate at the right side of the object velocity, and the contrary at South hemisphere. In conclusion, we have</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1. Coriolis force is perpendicular to the object velocity.
2. In the North hemisphere, C at V's right side.
3. In the South hemisphere, C at V's left side.
</code></pre></div></div>]]></content><author><name></name></author><category term="classic-mechanics"/><summary type="html"><![CDATA[a review of Coriolis force]]></summary></entry><entry><title type="html">From Newton’s Law to Navier-Stokes Equations</title><link href="https://shawnzou717.github.io/blog/2023/navier-stokes-equation/" rel="alternate" type="text/html" title="From Newton’s Law to Navier-Stokes Equations"/><published>2023-09-08T20:28:00+08:00</published><updated>2023-09-08T20:28:00+08:00</updated><id>https://shawnzou717.github.io/blog/2023/navier-stokes-equation</id><content type="html" xml:base="https://shawnzou717.github.io/blog/2023/navier-stokes-equation/"><![CDATA[<p><em>Sincere thanks to my kind classmate <strong>Xinghao Jiang</strong> for lending me the fluid mechanics textbook, which helped me review the fundamentals of fluid mechanics.</em></p> <h2 id="introduction-of-navier-stokes-equations">Introduction of Navier-Stokes Equations</h2> <hr/> <p>The <code class="language-plaintext highlighter-rouge">Navier-Stokes equations</code>, abbreviated as NS, is an equation based on Newton’s second law that describes the motion of a given particle in a fluid using Euler notation. By solving this equation, we would be able to obtain the velocity field of the fluid and thus understand its motion, making it valuable in fields such as precision instrument manufacturing and oceanographic research.</p> <p>We are all very familiar with Newton’s second law, which states that the net force acting on an object is equal to the product of its mass and acceleration, i.e. \(\boldsymbol{F}=m\boldsymbol{a}\). The bold symbol denotes a vector, meaning this variable has both magnitude and direction. If you replace the acceleration as the derivative of velocity \(\boldsymbol{V}\) with respect to time \(t\) yields a partial differential equation in terms of velocity. For an individual particle moving in infinite space, integrating both sides of the equation with respect to time gives us the particle’s motion equation. However, for a system of particles like a fluid, this method is no longer applicable due to the presence of the velocity field. That is when we introduce the <code class="language-plaintext highlighter-rouge">Euler Notation</code> and <code class="language-plaintext highlighter-rouge">material derivative</code>.</p> \[m\frac{d\boldsymbol{V}}{dt}=\boldsymbol{F}\rightrightarrows \boldsymbol{V}=\frac{\int{F}dt}{m} + \boldsymbol{V}_{0}\] <h2 id="euler-notation">Euler Notation</h2> <hr/> <p>Unlike a single particle, fluid can be considered as a set of continous particles. Therefore, we need to construct a function that describes the distribution of the motion state over the entire fluid space, which is stated as a field function. The most intuitive method is to assume that the velocity field function at a given point in space and time to be \(\boldsymbol{V}=\boldsymbol{V}(x,y,z,t)\). It should be noticed that here \((x,y,z)\) denotes a given position in space instead of the location of a given particle. In this way, if x, y, and z are given, the velocity field function represents the velocity of the fluid element that flows to that position at different times. This is so called <code class="language-plaintext highlighter-rouge">Euler Notation</code>. Other than velocity, any other kinds of physical variables can be expression following Eluer notation, such as temperature \(T\), position \(\boldsymbol{r}\), salinity\(S\), and so on. In addition, there is also the <code class="language-plaintext highlighter-rouge">Lagrangian Notation</code>, but we won’t discuss it in detail here.</p> <h2 id="material-derivative">Material Derivative</h2> <hr/> <p>However, the Euler notation introduces a new problem: how to represent the motion state of a given particle using Euler notation in fluid? Don’t panic, we can simply assume that there is a given particle in the fluid, and during time \(\delta t\), it moves from point A to point B with a certain velocity. The spatial and temporal location of A and B are respectively \((x,y,z,t), (x+\delta x, y+\delta y, z+\delta z, t+\delta t)\). We can use the Euler notation to describe its acceleration during this process.</p> \[\boldsymbol{a}=\frac{\boldsymbol{V}(x+\delta x, y+\delta y, z+\delta z, t+\delta t)-\boldsymbol{V}(x,y,z,t)}{\delta t}\] <p>Let the velocity be continously differentiable. This allows us to expand \(\boldsymbol{V}(x+\delta x, y+\delta y, z+\delta z, t+\delta t)\) to the first order.</p> \[\boldsymbol{V}(x+\delta x, y+\delta y, z+\delta z, t+\delta t) = \boldsymbol{V}(x,y,z,t) + \frac{\partial \boldsymbol{V}}{\partial x}\delta x + \frac{\partial \boldsymbol{V}}{\partial y}\delta y + \frac{\partial \boldsymbol{V}}{\partial z}\delta z + \frac{\partial \boldsymbol{V}}{\partial t}\delta t\] <p>Now, substituting the above expressiono into the acceleration equation, and supposing we have a very very small duration of time, i.e. let \(\delta t \rightarrow 0\), then we would have</p> \[\lim_{\delta t\to 0} \boldsymbol{a} = \frac{\partial \boldsymbol{V}}{\partial x}\frac{\partial x}{\partial t} + \frac{\partial \boldsymbol{V}}{\partial y}\frac{\partial y}{\partial t} + \frac{\partial \boldsymbol{V}}{\partial z}\frac{\partial z}{\partial t} + \frac{\partial \boldsymbol{V}}{\partial t}\] <p>To simplify the above expression, let \(u, v, w\) be the velocity projection along \(x, y, z\) axes. And the capital letter \(D=\partial/\partial t+(\boldsymbol{V}\cdot\nabla)\), in this way, we can orgnize the above equation into a more simplified form.</p> \[\lim_{\delta t\to 0} \boldsymbol{a} = \frac{D\boldsymbol{V}}{Dt}\] <p>Not only can the velocity of a particle be expressed in this way, but the change rate of all physical quantities for a given particle in a fluid can be written in this form. For example, the temperature variation rate of a given particle in the fluid is</p> \[\frac{DT}{Dt}=\frac{\partial T}{\partial t}+(\boldsymbol{V}\cdot\nabla)T\] <p>Now, this representation of the change rate of physical quantities for a particle in a fluid with respect to time is called the <code class="language-plaintext highlighter-rouge">material derivative</code>.</p> <h2 id="newtons-second-law-to-ns-equations">Newton’s Second Law to NS Equations</h2> <hr/> <p>With the help of material derivative, we are able to describe the second Newton’s law in the fluid.</p> \[\begin{aligned} \rho\frac{D\boldsymbol{V}}{Dt}=\boldsymbol{f}\\ \frac{\partial \boldsymbol{V}}{\partial t}+(\boldsymbol{V}\cdot\nabla)\boldsymbol{V}=\frac{\boldsymbol{f}}{\rho} \end{aligned}\] <p>Note that here \(\rho\) stands for the density of fluid, normally we assume the fluid to be incompressible so that \(\rho\) becomes constant. If the fluid is comressible, then there would be a density field as well, which would make the expression become much more complicated. Now, with incompressible fluid assumption, once the force density is substituted into the equation, the motion of the fluid under the specific force can be obtained.</p> <p>This leads us to a new question. How many kinds of forces are there? Gravity for sure. But what about pressure stress and viscous stress. Here let us solve it one by one.</p> <h2 id="pressure-stress">Pressure Stress</h2> <hr/> <p>Apart from gravity, water particles are also subjected to pressure in the opposite direction of the normal to the force surface. To visualize this process, we normally assume a cubic element in the fluid space. See figure below.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/ns-equations/underwater-pressure-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/ns-equations/underwater-pressure-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/ns-equations/underwater-pressure-1400.webp"/> <img src="/assets/img/ns-equations/underwater-pressure.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Surface pressure of the cubic fluid element </div> <p>\(p\) denotes the pressure at the center position of the cubic fluid element. Since the size of the cubic element is extremely small, we can replace the pressure difference \(\Delta p_{x}\) between center position and the cubic surface with the product of first-time derivative and the their distance \(\frac{\partial p}{\partial x}\frac{\delta x}{2}\). That gives us the expressions in the above figure.</p> <p>Now, pressure stress can be easily calculated by multiplying pressure with the area of surfaces.</p> <ul> <li>Pressure stress along along positive direction of x axis.</li> </ul> \[(p-\frac{\partial p}{\partial x}\frac{\delta x}{2})\delta y\delta z - (p+\frac{\partial p}{\partial x}\frac{\delta x}{2})\delta y\delta z = -\frac{\partial p}{\partial x}\delta x\delta y\delta z\] <ul> <li>Pressure stress along along positive direction of y axis.</li> </ul> \[(p-\frac{\partial p}{\partial y}\frac{\delta y}{2})\delta x\delta z - (p+\frac{\partial p}{\partial y}\frac{\delta y}{2})\delta x\delta z = -\frac{\partial p}{\partial y}\delta x\delta y\delta z\] <ul> <li>Pressure stress along along positive direction of z axis.</li> </ul> \[(p-\frac{\partial p}{\partial z}\frac{\delta z}{2})\delta x\delta y - (p+\frac{\partial p}{\partial z}\frac{\delta z}{2})\delta x\delta y = -\frac{\partial p}{\partial z}\delta x\delta y\delta z\] <p>The total pressure stress the cubic fluid element subjected to is</p> \[-\nabla p\times\delta x\delta y\delta z\] <p>Thus, the pressure stress density is \(-\nabla p\).</p> <h2 id="viscous-stress">Viscous Stress</h2> <p>Unlike pressure stress, viscous stress differs in magnitude and amplitude at different positions. For example, for a given surface perpendicular to x axis, the viscous stress varies quite rapidly, making it rather difficult to describe it by simply a normal vector.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/ns-equations/viscous-stress-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/ns-equations/viscous-stress-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/ns-equations/viscous-stress-1400.webp"/> <img src="/assets/img/ns-equations/viscous-stress.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>\(\tau_{x}\) denotes the viscous stress whom the plane is subjected to.</p> <p>How can we desribe this complicated forces now? Well, we just need to further decompose the viscous stress into 3 dimensions, for example we let \(\boldsymbol{\tau_x}=\tau_{xx}\boldsymbol{i}+\tau_{xy}\boldsymbol{j}+\tau_{xz}\boldsymbol{k}\). Similarly, the viscous stress at y-perpendicular and z-perpendicular plane can be decomposed as \(\boldsymbol{\tau_y}=\tau_{yx}\boldsymbol{i}+\tau_{yy}\boldsymbol{j}+\tau_{yz}\boldsymbol{k}\) and \(\boldsymbol{\tau_z}=\tau_{zx}\boldsymbol{i}+\tau_{zy}\boldsymbol{j}+\tau_{zz}\boldsymbol{k}\). Remember that the first subscript means which plane the viscous stress is applied to, and the second subscript means the direction of the viscous stress. With the help of further decomposed analysis, we reorgnize the viscous stress to 3 axis by adding the same direction viscous projection, i.e.</p> \[\begin{aligned} \tau_{sx}=\tau_{xx}+\tau_{yx}+\tau_{zx}\\ \tau_{sy}=\tau_{xy}+\tau_{yy}+\tau_{zy}\\ \tau_{sz}=\tau_{xz}+\tau_{yz}+\tau_{zz} \end{aligned}\] <p>The subscript \(sx\) means this physical parameter is parallel to the positive direction of x axis.</p>]]></content><author><name></name></author><category term="physical-oceanography"/><category term="Fluid"/><summary type="html"><![CDATA[a review of Navier-Stokes Equations]]></summary></entry><entry><title type="html">Transformer Analysis</title><link href="https://shawnzou717.github.io/blog/2023/transformer-analysis/" rel="alternate" type="text/html" title="Transformer Analysis"/><published>2023-08-03T11:57:00+08:00</published><updated>2023-08-03T11:57:00+08:00</updated><id>https://shawnzou717.github.io/blog/2023/transformer-analysis</id><content type="html" xml:base="https://shawnzou717.github.io/blog/2023/transformer-analysis/"><![CDATA[<p>Recently, a great personal assistant and chit-chat robot ChatGPT gained a lot of attention. Unlike other wooden voice assistants on our phones such as Siri, ChatGPT can process textual and semantic information in natural language, meaning it can talk to people continuously on a given topic and understand undelying meanings. Find it hard to believe? Let’s have a try.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/transformer-analysis/ChatGPT_joke-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/transformer-analysis/ChatGPT_joke-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/transformer-analysis/ChatGPT_joke-1400.webp"/> <img src="/assets/img/transformer-analysis/ChatGPT_joke.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>You can see that not only can ChatGPT keep the conversation but also give natural responses to my PhD joke. Why is it so fluent and elegant? What sets ChatGPT apart from Siri and Bixby? The reason is the powerful informatic extraction ability of ChatGPT’s submodule, Transformer. Transformer’s application extends way out of NLP domain. As a powerful mathematical tool, it has helped us in DNA recognition, medical research and many aspects in other research area. I believe it is safe to say that one day we may all need to apply this model in our project. Thus, a solid understanding of Transformer architecture is neccesary. To this end, this blog focuses on a comprehensive introduction of Transformer.</p> <h2 id="1-transformer-architecture">1. Transformer Architecture</h2> <hr/> <p>In 2017, Google posted a paper named <a href="https://arxiv.org/abs/1706.03762v4">Attention is All You Need</a> in arXiv bringing Transformer into history. Though Transformer follows the <code class="language-plaintext highlighter-rouge">seq2seq</code> structure (also known as <code class="language-plaintext highlighter-rouge">decoders and encoders</code>), its encoders and decoders consist of sole <code class="language-plaintext highlighter-rouge">self-attention</code> modules instead of <code class="language-plaintext highlighter-rouge">RNN</code> and <code class="language-plaintext highlighter-rouge">CNN</code> like most other NLP models. This is exactly the origin of the article title, a neural network composed entirely of self-attention mechanisms. Now let’s take the classic Transformer as an example reviewing this unique model. Below shows a simplified Transformer structure and detail composition of encoders and decoders.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/transformer-analysis/transformer-entire-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/transformer-analysis/transformer-entire-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/transformer-analysis/transformer-entire-1400.webp"/> <img src="/assets/img/transformer-analysis/transformer-entire.png" class="img-fluid d-block mx-auto rounded z-depth-1" width="auto" height="60%" max-width="60%" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Simplified Transformer Structure </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/transformer-analysis/transformer-en-decoders-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/transformer-analysis/transformer-en-decoders-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/transformer-analysis/transformer-en-decoders-1400.webp"/> <img src="/assets/img/transformer-analysis/transformer-en-decoders.png" class="img-fluid d-block mx-auto rounded z-depth-1" width="auto" height="60%" max-width="60%" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Transformer encoders and decoders </div> <p>Transformer model stacks 6 encoders and 6 decoders, ahead by a source embedding and a target embedding networks, end with a softmax classifier. Embedding units can be self-constructed algorithms or pre-trained networks such as <code class="language-plaintext highlighter-rouge">Word2Vec</code>. The encoder and decoder have a very similar structure, only that the decoder has one extra layer of <code class="language-plaintext highlighter-rouge">ADD &amp; NORM</code> and one extra layer of <code class="language-plaintext highlighter-rouge">multi-head attention</code>. In addition, it should be noted that a <code class="language-plaintext highlighter-rouge">mask operation</code> has been added to the 1st multi-head attention layer of each decoder, which aims to use the seq2seq structure while ensuring the parallelism of the network. The softmax classifier consists of a <code class="language-plaintext highlighter-rouge">linear transformation</code> and a <code class="language-plaintext highlighter-rouge">softmax</code> layer. To know more technique details of these operators, let’s start orgnize the forward propagation of Transformer.</p> <h2 id="2-forward-propagation">2. Forward Propagation</h2> <hr/> <h3 id="21-word-embedding">2.1 Word Embedding</h3> <p>Before we go further, I’d like to give you some preliminary knowledge about word encoding, that is the method for digitalizing human words as computers are not capable of recognizing human language sympols. The most widely used ones are <code class="language-plaintext highlighter-rouge">one-hot encoding</code> and <code class="language-plaintext highlighter-rouge">word embedding</code> methods.</p> <ul> <li> <p><strong>One-hot encoding</strong></p> <p>One-hot encoding is a technique that transfers words into binary vector where each value represent one word in the lexicon. For a given word, the value at its corresponding position is turned on (set to be 1) while the others remain turned off (set to be 0). For example, we have RGB Tricolor, each color can be expressed by the following vectors:</p> <table> <thead> <tr> <th style="text-align: center">Color</th> <th style="text-align: center">Vector</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">red</td> <td style="text-align: center">[1, 0, 0]</td> </tr> <tr> <td style="text-align: center">green</td> <td style="text-align: center">[0, 1, 0]</td> </tr> <tr> <td style="text-align: center">blue</td> <td style="text-align: center">[0, 0, 1]</td> </tr> </tbody> </table> <p>Though one-hot encoding solves the words digitalizing problem, the produced vector cannot be directly applied in the neural networks. Because neural networks are actually nothing else but layered matrix computations. While one-hot vectors combined together form a sparse matrix. This kind of matrix has far more 0 valued elements than other effective elements leading to a very low informatic density, i.e. a very small informatic volume and an extremely large matrix size. As a result, neural network models would suffer from huge computation complexity increases and only gain very poor language processing ability.</p> </li> <li> <p><strong>Word embedding</strong></p> <p>To tackle this problem, <code class="language-plaintext highlighter-rouge">word embedding</code> is proposed. This method aims to represent words with a intensive vector in a high dimension space, meanwhile the distance among vectors represent the textual and semantic similarity of their corresponding words. For example, all the words descripe emotions such as <strong>happy</strong> and <strong>sad</strong> should concentrate in one area after word embedding.</p> </li> </ul> <p>There are some widely used word embedding methods including <code class="language-plaintext highlighter-rouge">Word2Vec</code>, <code class="language-plaintext highlighter-rouge">FastText</code> and <code class="language-plaintext highlighter-rouge">GloVe</code>. Wanna know more? Try asking ChatGPT about it. Classic Transformer uses a customized embedding unit containing a linear Transformation and a softmax layer. To specify the parameter shape, we assume this Transformer is used for translating English to Germany with both 32,000 words lexicon. Then the data flow and shape variation of word embedding can be shown in the following figure.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/transformer-analysis/word_embedding-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/transformer-analysis/word_embedding-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/transformer-analysis/word_embedding-1400.webp"/> <img src="/assets/img/transformer-analysis/word_embedding.jpg" class="img-fluid d-block mx-auto rounded z-depth-1" width="auto" height="60%" max-width="60%" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Word embedding structure </div> <p>It’s worth noticing that before we can put words into Transformer, sentences are first one-hot encoded, then compressed from 32000 to 512 in size by the following word embedding unit. Normally, for convenience and consistency, source and target embedding take the same size of embedded vector. Sure you can change the parameter shape to whatever you like. But here we follow the above convention.</p> <h3 id="22-position-embedding">2.2 Position Embedding</h3> <p>Position embedding works just like word embedding, only it aims to encode the position information of each word into the embedded vector. The most straightforward way is using word’s natural rank index within the sentence. However, embedded word vector usually possess an absolute amplitude smaller than 1, large rank index can totally erase or hide the effective sematic and textual message of a word. That is when we induced triangle-function encoding function. For a given word embedded vector, in this case the output of word embedding unit, the position embedding vector can be generated according to the following equation.</p> \[P(s, d)= \begin{cases} sin(\frac{s}{10000^{\frac{2i}{D}}}), &amp; s = 2i\\ cos(\frac{s}{10000^{\frac{2i+1}{D}}}), &amp; s = 2i+1 \end{cases}\] <p>$D=512$, denotes the maximum value of $d$. Each position generated an unique vector to represent the relative position relation among words. To attach these informations, position embedded vector and word embedded vector should be added together directly. Don’t doubt your eyes, just easily add them like below.</p> \[O_{position_embedding}(n,s,d)=O_{word\_ embedding}(n,s,d)+P(s, d)\] <h3 id="23-encoder-and-decoder">2.3 Encoder and Decoder</h3> <p>Encoder and decoder can be the most difficult part of Transformer though it is composed of many simple submodules as many innovative operations have been adopted. Such as <code class="language-plaintext highlighter-rouge">mask</code> operation in the decoder. Fortunately, encoder and decoder share similar architectures, thus we divide them into 3 basic units, there are <code class="language-plaintext highlighter-rouge">ADD &amp; NORM</code>, <code class="language-plaintext highlighter-rouge">FFN</code>, and <code class="language-plaintext highlighter-rouge">Multi-head Attention (masked or not one)</code>.</p> <h4 id="231-add--norm">2.3.1 ADD &amp; NORM</h4> <p><code class="language-plaintext highlighter-rouge">ADD &amp; NORM</code> is composed by a <code class="language-plaintext highlighter-rouge">ADD</code> and a <code class="language-plaintext highlighter-rouge">Layer Normalization</code> operations. ADD operation is implemented by element-wise summing tensors, and is commonly used in residual networks, an commonly used unit for raising NN performance by increasing the depth of NN while making gradient backpropagation reachable to the shallow layers. Whether from the forward or backward propagation side, ADD has the simplest form among all operators. Therefore, we don’t talk too much about it here.</p> <p>Whereas when it comes to “Normalization”, situations become far more complicated. You might know <code class="language-plaintext highlighter-rouge">batch normalization</code> well. In image-processing neural networks, convolution always follows a BN operation to zerolize and rescale data distribution. BN is helpful in speeding up training process and stabilizing amplitude range of data. Unfortunately, BN is not suitable for NLP tasks due to the huge difference of data features between image and human language. Till now there are still many discussions about the pros and cons of BN and LN. If you are confused about the selection between them, the best way is to review relevant papers. Here we only introduce how the LN is done in Transformer.</p> <p>Unlike BN, LN redistribute data within the embedded vector range, i.e. each word’s embedded vector subtracts its expectation and is then divided by its variance. Combining our assumption on the parameter shapes above, LN equation looks like this:</p> \[O_{LN}(n,s,d)= \frac{I_{LN}(n,s,d)-\mu\left(I_{LN}(n,s,:)\right)} {\sqrt{\sigma^{2}(I_{LN}(n,s,:))+\epsilon}} \times\gamma(d)+\beta(d)\] <p>\(\mu\left(I_{LN}(n,s,:)\right)\) denotes the mean value of \(I_{LN}\) along \(d\) dimension. \(\sigma^{2}(I_{LN}(n,s,:))\) denotes the variance of \(I_{LN}\) along \(d\) dimension. \(\epsilon\) is of very small magnitude to avoid deviding zero. \(\gamma, \beta\) are learnable parameters of length \(D(=512)\).</p> <h4 id="232-feed-forward-network">2.3.2 Feed Forward Network</h4> <h4 id="233-multi-head-attention">2.3.3 Multi-head Attention</h4> <h3 id="24-softmax-classifier">2.4 Softmax Classifier</h3> <h2 id="3-backward-propagation">3 Backward Propagation</h2> <hr/>]]></content><author><name></name></author><category term="deep-learning"/><category term="Transformer"/><summary type="html"><![CDATA[a plain introduction of Transformer and professional derivation of its forward and backward propagation]]></summary></entry></feed>